 xOnlyData <- myDataClean[,-1]
> # Let us apply kmeans for k=3 clusters 
> kmm = kmeans(xOnlyData, 3, nstart = 50, iter.max = 15) 
> # We keep number of iter.max=15 to ensure the algorithm converges and nstart=50 to 
> # Ensure that atleat 50 random sets are choosen  
> kmm
K-means clustering with 3 clusters of sizes 2497, 1923, 1034

Cluster means:
  churches  resorts  beaches    parks theatres  museums    malls     zoos restaurants     pubs  burgers lodgings juicebars galleries
1 1.088602 1.936304 1.908074 2.092367 2.272287 2.745503 3.945779 3.078811    4.007633 3.524782 2.472375 2.540388  2.894401  2.849495
2 1.488263 2.616095 3.221685 3.981050 4.333131 3.623157 3.313349 2.357561    2.686500 2.593666 1.910614 1.907738  1.449022  1.279319
3 2.281886 2.696170 2.529565 2.297099 2.061267 1.893501 1.987205 1.584333    1.817176 1.605919 1.439043 1.530261  1.869255  2.376180
     clubs     pools      gyms  bakeries      spas     cafes viewpoints monuments  gardens
1 1.040593 0.7567521 0.6068522 0.7081778 0.7337445 0.7013777  0.9706728 0.8962675 1.054341
2 1.113994 0.7237650 0.5435777 0.5621009 0.7616745 0.8504836  2.2393240 1.8739314 1.696620
3 1.706451 1.8339845 1.8621277 2.3569149 2.0842360 1.8160445  2.7185106 2.4263056 2.530039

Clustering vector:
   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  [64] 2 2 2 2 1 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1
 [127] 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1
 [190] 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [253] 1 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1 2 1 1 1 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3
 [316] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [379] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 2 1 1 1 1 2 2 2 1 1 1 2 1 2 1 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2
 [442] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [505] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [568] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [631] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [694] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3
 [757] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 [820] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 3 3 3 3
 [883] 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 2 3 2 2 3 3 2 3 3 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2 2 3 2 3 2 2 2 2 2 2 2
 [946] 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1
 [ reached getOption("max.print") -- omitted 4454 entries ]

Within cluster sum of squares by cluster:
[1] 70552.18 54996.25 31413.50
 (between_SS / total_SS =  23.5 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"     "tot.withinss" "betweenss"    "size"         "iter"        
[9] "ifault"      
> # Elbow Method for finding the optimal number of clusters
> set.seed(123)
> # Compute and plot wss for k = 2 to k = 15.
> k.max <- 15
> wss <- sapply(1:k.max, function(k){kmeans(xOnlyData, k, nstart=50,iter.max = 15 )$tot.withinss})
> wss
 [1] 205180.62 174829.19 156961.93 142374.04 133356.76 126756.11 121624.97 117361.89 113334.02 109610.30 106504.88 103813.16
[13] 101676.04  99154.49  97368.68
> plot(1:k.max, wss,
+      type="b", pch = 19, frame = FALSE, 
+      xlab="Number of clusters K",
+      ylab="Total within-clusters sum of squares")
> install.packages("mclust")
Installing package into ‘/home/teddybear/R/x86_64-pc-linux-gnu-library/3.4’
(as ‘lib’ is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/mclust_5.4.5.tar.gz'
Content type 'application/x-gzip' length 2873339 bytes (2.7 MB)
==================================================
downloaded 2.7 MB

* installing *source* package ‘mclust’ ...
** package ‘mclust’ successfully unpacked and MD5 sums checked
** libs
gfortran   -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-AitvI6/r-base-3.4.4=. -fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-AitvI6/r-base-3.4.4=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
gfortran   -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-AitvI6/r-base-3.4.4=. -fstack-protector-strong  -c mclust.f -o mclust.o
gfortran   -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-AitvI6/r-base-3.4.4=. -fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
g++ -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions -Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o -llapack -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
installing to /home/teddybear/R/x86_64-pc-linux-gnu-library/3.4/mclust/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
*** copying figures
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (mclust)

The downloaded source packages are in
	‘/tmp/RtmplGBH5U/downloaded_packages’
> # Bayesian Inference Criterion for k means to validate choice from Elbow Method
> d_clust <- Mclust(as.matrix(xOnlyData), G=1:15, 
+                   modelNames = mclust.options("emModelNames"))
Error in Mclust(as.matrix(xOnlyData), G = 1:15, modelNames = mclust.options("emModelNames")) : 
  could not find function "Mclust"
> library(mclust)
    __  ___________    __  _____________
   /  |/  / ____/ /   / / / / ___/_  __/
  / /|_/ / /   / /   / / / /\__ \ / /   
 / /  / / /___/ /___/ /_/ /___/ // /    
/_/  /_/\____/_____/\____//____//_/    version 5.4.5
Type 'citation("mclust")' for citing this R package in publications.

Attaching package: ‘mclust’

The following object is masked from ‘package:purrr’:

    map

> i
Error: object 'i' not found
> # Bayesian Inference Criterion for k means to validate choice from Elbow Method
> d_clust <- Mclust(as.matrix(xOnlyData), G=1:15, 
+                   modelNames = mclust.options("emModelNames"))
fitting ...
  |===========================================================================================================================| 100%
> d_clust$BIC
Bayesian Information Criterion (BIC): 
         EII       VII       EEI       VEI       EVI       VVI       EEE       EVE       VEE       VVE       EEV       VEV       EVV
1  -417918.9 -417918.9 -410766.5 -410766.5 -410766.5 -410766.5 -374293.9 -374293.9 -374293.9 -374293.9 -374293.9 -374293.9 -374293.9
2  -405071.8 -406621.0 -397131.5 -392601.8 -388926.9 -390606.3 -370002.7 -342911.4 -367456.7 -361753.5 -339603.6 -361899.3 -343890.0
3  -395478.3 -394402.7 -390318.8 -382931.4 -347028.9 -353410.1 -365679.8 -319438.2 -360417.4 -317843.4 -306810.7 -318957.7 -302132.3
4  -386483.7 -386689.8 -377459.1 -375198.0        NA        NA -362865.3        NA        NA        NA -292229.5 -311702.4        NA
5  -382978.4 -377395.4 -373534.9 -367443.6        NA        NA -359966.2        NA        NA        NA -275450.7 -286252.3        NA
6  -379999.3 -372611.7 -369467.8 -362809.6        NA        NA -352718.8        NA        NA        NA -256192.1 -281694.1        NA
7  -376226.5 -369372.0 -361290.1 -359659.6        NA        NA -351113.2        NA        NA        NA -264609.0 -278051.4        NA
8  -372580.4 -365453.9 -359406.3 -356617.2        NA        NA -349876.5        NA        NA        NA -260433.1 -275515.8        NA
9  -368619.2 -362368.3 -357297.6 -352000.9        NA        NA -344843.7        NA        NA        NA -263310.9 -255722.5        NA
10 -365767.8 -361193.5 -354748.2 -345110.5        NA        NA -341228.5        NA        NA        NA -247969.1 -256516.9        NA
11 -365768.4 -357459.9 -352513.7 -344921.6        NA        NA -340402.8        NA        NA        NA -247193.5 -256110.6        NA
12 -363197.6 -355823.6 -350763.1 -341731.9        NA        NA -335075.8        NA        NA        NA -242470.6 -233027.5        NA
13 -361985.6 -352861.9 -349518.9 -339490.3        NA        NA -333771.1        NA        NA        NA -238038.8 -228075.5        NA
14 -360016.8 -350813.3 -347401.3 -334887.8        NA        NA -333131.3        NA        NA        NA -232544.1 -228304.0        NA
15 -356586.5 -348352.3 -345484.6 -330834.0        NA        NA -330019.5        NA        NA        NA -229319.5 -224523.2        NA
         VVV
1  -374293.9
2  -358955.4
3  -311399.9
4         NA
5         NA
6         NA
7         NA
8         NA
9         NA
10        NA
11        NA
12        NA
13        NA
14        NA
15        NA

Top 3 models based on the BIC criterion: 
   VEV,15    VEV,13    VEV,14 
-224523.2 -228075.5 -228304.0 
> plot(d_clust)
Model-based clustering plots: 

1: BIC
2: classification
3: uncertainty
4: density

Selection: 1
Model-based clustering plots: 

1: BIC
2: classification
3: uncertainty
4: density

Selection: install.packages("NbClust",dependencies = TRUE)
Enter an item from the menu, or 0 to exit
Selection: 
Enter an item from the menu, or 0 to exit
Selection: 0
> install.packages("NbClust",dependencies = TRUE)
Installing package into ‘/home/teddybear/R/x86_64-pc-linux-gnu-library/3.4’
(as ‘lib’ is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/NbClust_3.0.tar.gz'
Content type 'application/x-gzip' length 22211 bytes (21 KB)
==================================================
downloaded 21 KB

* installing *source* package ‘NbClust’ ...
** package ‘NbClust’ successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (NbClust)

The downloaded source packages are in
	‘/tmp/RtmplGBH5U/downloaded_packages’
> library(NbClust)
> nb <- NbClust(scaled_data, diss=NULL, distance = "euclidean", 
+               min.nc=2, max.nc=5, method = "kmeans", 
+               index = "all", alphaBeale = 0.1)
Error in NbClust(scaled_data, diss = NULL, distance = "euclidean", min.nc = 2,  : 
  object 'scaled_data' not found
> nb <- NbClust(xOnlyData, diss=NULL, distance = "euclidean", 
+               min.nc=2, max.nc=5, method = "kmeans", 
+               index = "all", alphaBeale = 0.1)
*** : The Hubert index is a graphical method of determining the number of clusters.
                In the plot of Hubert index, we seek a significant knee that corresponds to a 
                significant increase of the value of the measure i.e the significant peak in Hubert
                index second differences plot. 
 
*** : The D index is a graphical method of determining the number of clusters. 
                In the plot of D index, we seek a significant knee (the significant peak in Dindex
                second differences plot) that corresponds to a significant increase of the value of
                the measure. 
 
******************************************************************* 
* Among all indices:                                                
* 7 proposed 2 as the best number of clusters 
* 3 proposed 3 as the best number of clusters 
* 12 proposed 4 as the best number of clusters 
* 1 proposed 5 as the best number of clusters 

                   ***** Conclusion *****                            
 
* According to the majority rule, the best number of clusters is  4 
 
 
******************************************************************* 
> hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))
> # Elbow Method for finding the optimal number of clusters
> set.seed(123)
> # Compute and plot wss for k = 2 to k = 15.
> k.max <- 20
> wss <- sapply(1:k.max, function(k){kmeans(xOnlyData, k, nstart=50,iter.max = 15 )$tot.withinss})
> wss
 [1] 205180.62 174829.19 156961.93 142374.04 133356.76 126756.11 121624.97 117361.89 113334.02 109610.30 106504.88 103813.16
[13] 101676.04  99154.49  97368.68  95746.20  93624.83  91619.13  90650.20  88629.51
> plot(1:k.max, wss,
+      type="b", pch = 19, frame = FALSE, 
+      xlab="Number of clusters K",
+      ylab="Total within-clusters sum of squares")
> # Compute and plot wss for k = 2 to k = 15.
> k.max <- 30
> wss <- sapply(1:k.max, function(k){kmeans(xOnlyData, k, nstart=50,iter.max = 15 )$tot.withinss})
> wss
 [1] 205180.62 174829.19 156962.15 142374.04 133356.76 126756.11 121624.97 117361.89 113334.28 109628.86 106778.60 103808.70
[13] 101732.90  99468.44  97048.36  95581.09  93732.73  92186.96  89840.64  88803.53  87996.20  86571.76  84981.70  83762.40
[25]  82355.87  81776.07  80156.92  79145.20  77779.66  77575.26
> plot(1:k.max, wss,
+      type="b", pch = 19, frame = FALSE, 
+      xlab="Number of clusters K",
+      ylab="Total within-clusters sum of squares")
> # Bayesian Inference Criterion for k means to validate choice from Elbow Method
> d_clust <- Mclust(as.matrix(xOnlyData), G=1:30, 
+                   modelNames = mclust.options("emModelNames"))
fitting ...
  |===========================================================================================================================| 100%
> d_clust$BIC
Bayesian Information Criterion (BIC): 
         EII       VII       EEI       VEI       EVI       VVI       EEE       EVE       VEE       VVE       EEV       VEV       EVV
1  -417918.9 -417918.9 -410766.5 -410766.5 -410766.5 -410766.5 -374293.9 -374293.9 -374293.9 -374293.9 -374293.9 -374293.9 -374293.9
2  -405100.5 -404565.6 -397021.6 -392601.5 -372024.0 -368358.6 -370917.8 -335179.8 -365705.2 -327696.8 -334935.1 -330420.7 -331575.0
3  -395489.7 -393063.7 -388163.0 -382347.1        NA        NA -367151.9        NA        NA        NA -326369.4 -317791.0        NA
4  -386482.5 -384741.6 -377458.4 -370959.5        NA        NA -362865.9        NA        NA        NA -293313.2 -306145.8        NA
5  -382972.5 -377048.1 -373535.6 -365872.4        NA        NA -360398.3        NA        NA        NA -274242.2 -282371.9        NA
6  -377128.2 -372562.7 -366095.1 -359299.4        NA        NA -354275.6        NA        NA        NA -268429.1 -266652.3        NA
7  -373164.0 -367755.6 -359977.7 -356636.1        NA        NA -351690.0        NA        NA        NA -270113.8 -264142.6        NA
8  -372021.2 -364367.9 -356861.7 -351104.5        NA        NA -345965.7        NA        NA        NA -258628.8 -259116.7        NA
9  -368587.0 -363370.7 -354601.4 -348911.6        NA        NA -344231.7        NA        NA        NA -257055.0 -257137.4        NA
10 -367128.9 -361887.2 -353794.6 -345425.6        NA        NA -341895.9        NA        NA        NA -246591.4 -247200.3        NA
11 -364548.0 -357706.0 -351997.3 -342541.2        NA        NA -338826.3        NA        NA        NA -242415.6 -249518.8        NA
12 -363518.5 -355168.4 -349913.1 -340301.3        NA        NA -334255.3        NA        NA        NA -241837.9 -246693.6        NA
13 -360473.3 -352853.2 -346091.0 -335723.7        NA        NA -332286.3        NA        NA        NA -233301.1 -236890.0        NA
14 -358604.3 -351302.1 -345189.4 -333704.1        NA        NA -330666.7        NA        NA        NA -248287.1 -235232.7        NA
15 -355659.2 -348725.2 -342824.7 -331521.0        NA        NA -329844.0        NA        NA        NA -241375.9 -230479.6        NA
16 -354522.8 -347080.0 -341526.1 -328738.0        NA        NA -329128.8        NA        NA        NA -239685.9 -223048.3        NA
17 -353917.3 -346512.8 -340814.4 -325378.5        NA        NA -326793.1        NA        NA        NA -235410.6 -210185.7        NA
18 -353298.4 -344936.4 -336818.1 -323531.0        NA        NA -325512.6        NA        NA        NA -236432.6 -204971.6        NA
19 -351302.6 -342780.9 -335853.8 -322646.5        NA        NA -325396.7        NA        NA        NA -238635.5 -205055.9        NA
20 -349122.0 -339703.8 -333779.6 -320610.4        NA        NA -324672.7        NA        NA        NA -244088.1 -202726.7        NA
21 -348037.0 -337502.5 -333017.5 -319965.1        NA        NA -323659.1        NA        NA        NA -238804.5 -201233.0        NA
22 -347030.3 -335914.8 -331828.4 -317610.3        NA        NA -322340.0        NA        NA        NA -229781.7 -196305.9        NA
23 -345058.2 -334112.1 -331491.3 -315890.9        NA        NA -322106.4        NA        NA        NA -230685.9 -196872.1        NA
24 -343531.6 -332708.8 -329991.5 -313797.5        NA        NA -320612.9        NA        NA        NA -227966.6 -193971.1        NA
25 -343278.7 -331884.5 -328935.4 -311990.5        NA        NA -319072.0        NA        NA        NA -223020.2 -193403.8        NA
26 -340438.0 -329939.2 -327816.2 -309524.4        NA        NA -318793.2        NA        NA        NA -226064.1 -187882.7        NA
27 -339716.3 -326822.3 -326816.3 -307168.7        NA        NA -318110.8        NA        NA        NA -224946.4 -194173.2        NA
28 -339081.4 -324930.5 -326360.1 -305774.8        NA        NA -317883.2        NA        NA        NA -223153.9 -194667.8        NA
29 -338199.9 -323441.8 -326393.6 -304825.0        NA        NA -317346.8        NA        NA        NA -221025.4 -190608.6        NA
30 -336867.3 -321507.7 -325678.7 -303037.2        NA        NA -317068.7        NA        NA        NA -222386.8 -194023.7        NA
         VVV
1  -374293.9
2  -323059.1
3         NA
4         NA
5         NA
6         NA
7         NA
8         NA
9         NA
10        NA
11        NA
12        NA
13        NA
14        NA
15        NA
16        NA
17        NA
18        NA
19        NA
20        NA
21        NA
22        NA
23        NA
24        NA
25        NA
26        NA
27        NA
28        NA
29        NA
30        NA

Top 3 models based on the BIC criterion: 
   VEV,26    VEV,29    VEV,25 
-187882.7 -190608.6 -193403.8 
> plot(d_clust)
Model-based clustering plots: 

1: BIC
2: classification
3: uncertainty
4: density

Selection: 1
Model-based clustering plots: 

1: BIC
2: classification
3: uncertainty
4: density

Selection: nb <- NbClust(xOnlyData, diss=NULL, distance = "euclidean", 
Enter an item from the menu, or 0 to exit
Selection:               min.nc=2, max.nc=20, method = "kmeans", 
Enter an item from the menu, or 0 to exit
Selection:               index = "all", alphaBeale = 0.1)
Enter an item from the menu, or 0 to exit
Selection: nb <- NbClust(xOnlyData, diss=NULL, distance = "euclidean", 
Enter an item from the menu, or 0 to exit
Selection:               min.nc=2, max.nc=20, method = "kmeans", 
Enter an item from the menu, or 0 to exit
Selection:               index = "all", alphaBeale = 0.1)
Enter an item from the menu, or 0 to exit
Selection: 0
> nb <- NbClust(xOnlyData, diss=NULL, distance = "euclidean", 
+               min.nc=2, max.nc=20, method = "kmeans", 
+               index = "all", alphaBeale = 0.1)

> hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))

> ?NbClust
> nb <- NbClust(xOnlyData, diss=NULL, distance = "euclidean", 
+               min.nc=15, max.nc=28, method = "kmeans", 
+               index = "all", alphaBeale = 0.1)
*** : The Hubert index is a graphical method of determining the number of clusters.
                In the plot of Hubert index, we seek a significant knee that corresponds to a 
                significant increase of the value of the measure i.e the significant peak in Hubert
                index second differences plot. 
 
*** : The D index is a graphical method of determining the number of clusters. 
                In the plot of D index, we seek a significant knee (the significant peak in Dindex
                second differences plot) that corresponds to a significant increase of the value of
                the measure. 
 
******************************************************************* 
* Among all indices:                                                
* 7 proposed 15 as the best number of clusters 
* 3 proposed 17 as the best number of clusters 
* 1 proposed 19 as the best number of clusters 
* 1 proposed 20 as the best number of clusters 
* 1 proposed 21 as the best number of clusters 
* 5 proposed 23 as the best number of clusters 
* 3 proposed 27 as the best number of clusters 
* 2 proposed 28 as the best number of clusters 

                   ***** Conclusion *****                            
 
* According to the majority rule, the best number of clusters is  15 
 
 
******************************************************************* 
> hist(nb$Best.nc[1,], breaks = max(na.omit(nb$Best.nc[1,])))
